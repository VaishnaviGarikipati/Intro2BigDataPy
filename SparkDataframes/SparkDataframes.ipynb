{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1a)Start a simple Spark Session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"walmart\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b)Load the Walmart Stock CSV file. Have Spark infer the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('gs://spark_df/walmart_stock.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1c)What are the column names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1d)What does the Schema look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1e)Print out the first 5 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date=datetime.datetime(2012, 1, 3, 0, 0), Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996),\n",
       " Row(Date=datetime.datetime(2012, 1, 4, 0, 0), Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475),\n",
       " Row(Date=datetime.datetime(2012, 1, 5, 0, 0), Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539),\n",
       " Row(Date=datetime.datetime(2012, 1, 6, 0, 0), Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922),\n",
       " Row(Date=datetime.datetime(2012, 1, 9, 0, 0), Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1f)Use describe() to learn about the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
      "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
      "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
      "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)There are too many decimal places for mean and stddev in the describe() dataframe. Format the numbers to just show up to two decimal places. Pay careful attention to the data types that .describe() returns. You won’t find how to do this exact formatting in the example code, but you can check this link for a hint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------+--------+--------+\n",
      "|summary|    Open|    High|     Low|   Close|  Volume|\n",
      "+-------+--------+--------+--------+--------+--------+\n",
      "|  count|1,258.00|1,258.00|1,258.00|1,258.00|    1258|\n",
      "|   mean|   72.36|   72.84|   71.92|   72.39| 8222093|\n",
      "| stddev|    6.77|    6.77|    6.74|    6.76| 4519780|\n",
      "|    min|   56.39|   57.06|   56.30|   56.42| 2094900|\n",
      "|    max|   90.80|   90.97|   89.25|   90.47|80898100|\n",
      "+-------+--------+--------+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = df.describe()\n",
    "result.select(result['summary'],\n",
    "              format_number(result['Open'].cast('float'),2).alias('Open'),\n",
    "              format_number(result['High'].cast('float'),2).alias('High'),\n",
    "              format_number(result['Low'].cast('float'),2).alias('Low'),\n",
    "              format_number(result['Close'].cast('float'),2).alias('Close'),\n",
    "              result['Volume'].cast('int').alias('Volume')\n",
    "             ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)Create a new dataframe with a column called HV Ratio that is the ratio of the High price versus Volume of stock traded for a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+--------+------------------+--------------------+\n",
      "|               Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|            HV Ratio|\n",
      "+-------------------+------------------+------------------+------------------+------------------+--------+------------------+--------------------+\n",
      "|2012-01-03 00:00:00|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|4.819714653321546E-6|\n",
      "|2012-01-04 00:00:00|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|6.290848613094555E-6|\n",
      "|2012-01-05 00:00:00|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|4.669412994783916E-6|\n",
      "|2012-01-06 00:00:00|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|7.367338463826307E-6|\n",
      "|2012-01-09 00:00:00|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|8.915604778943901E-6|\n",
      "|2012-01-10 00:00:00|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|8.644477436914568E-6|\n",
      "|2012-01-11 00:00:00|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|9.351828421515645E-6|\n",
      "|2012-01-12 00:00:00|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994| 8.29141562102703E-6|\n",
      "|2012-01-13 00:00:00|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|7.712212102001476E-6|\n",
      "|2012-01-17 00:00:00|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|7.071764823529412E-6|\n",
      "|2012-01-18 00:00:00|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|1.015495466386981E-5|\n",
      "|2012-01-19 00:00:00|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|6.576354146362592...|\n",
      "|2012-01-20 00:00:00|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996| 5.90145296180676E-6|\n",
      "|2012-01-23 00:00:00|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104|8.547679455011844E-6|\n",
      "|2012-01-24 00:00:00|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|8.420709512685392E-6|\n",
      "|2012-01-25 00:00:00|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001|1.041448341728929...|\n",
      "|2012-01-26 00:00:00|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436|8.316075414862431E-6|\n",
      "|2012-01-27 00:00:00|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|9.721183814992126E-6|\n",
      "|2012-01-30 00:00:00|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|8.029436027707578E-6|\n",
      "|2012-01-31 00:00:00|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006|6.307432259386365E-6|\n",
      "+-------------------+------------------+------------------+------------------+------------------+--------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2 = df.withColumn(\"HV Ratio\",df[\"High\"]/df[\"Volume\"])\n",
    "df_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4)What is the mean of the Close column? What is the max and min of the Volume column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+----------+\n",
      "|       avg(Close)|max(Close)|min(Close)|\n",
      "+-----------------+----------+----------+\n",
      "|72.38844998012726| 90.470001| 56.419998|\n",
      "+-----------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean,max,min\n",
    "df.select(mean(\"Close\"),max(\"Close\"),min(\"Close\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5)How many days was the Close lower than 60 dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['Close'] < 60).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6)What is the max High per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|Year|max(High)|\n",
      "+----+---------+\n",
      "|2015|90.970001|\n",
      "|2013|81.370003|\n",
      "|2014|88.089996|\n",
      "|2012|77.599998|\n",
      "|2016|75.190002|\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "year_df = df.withColumn(\"Year\",year(df[\"Date\"]))\n",
    "max_df = year_df.groupBy('Year').max()\n",
    "max_df.select('Year','max(High)').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average Close for each Calendar Month? In other words, across all the years, what is the average Close price for Jan, Feb, Mar, etc… Your result will have a value for each of these months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|Month|       avg(Close)|\n",
      "+-----+-----------------+\n",
      "|    1|71.44801958415842|\n",
      "|    2|  71.306804443299|\n",
      "|    3|71.77794377570092|\n",
      "|    4|72.97361900952382|\n",
      "|    5|72.30971688679247|\n",
      "|    6| 72.4953774245283|\n",
      "|    7|74.43971943925233|\n",
      "|    8|73.02981855454546|\n",
      "|    9|72.18411785294116|\n",
      "|   10|71.57854545454543|\n",
      "|   11| 72.1110893069307|\n",
      "|   12|72.84792478301885|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import month\n",
    "month_df = df.withColumn(\"Month\",month(\"Date\"))\n",
    "month_mean = month_df.select(\"Month\",\"Close\").groupBy(\"Month\").mean()\n",
    "month_mean.select(\"Month\",\"avg(Close)\").orderBy('Month').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
